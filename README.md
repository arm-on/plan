# Rules

1. Trust your professor
2. Accept that while working in a group, your achievement is not gonna be maximized since the problem also has other constraints (such as not hurting anyone's feelings).
3. Avoid doing / not doing something that makes you feel like a loser
# Reading

# Goals:

- Detect the Pros. and Cons.

# Items:

- PhD Thesis | ADVERSARIALLY ROBUST MACHINE LEARNING WITH GUARANTEES
- ANTIDOTE: Understanding and Defending against Poisoning of Anomaly Detectors
- Stronger Data Poisoning Attacks Break Data Sanitization Defenses
- SoK: The Faults in our ASRs: An Overview of Attacks against Automatic Speech Recognition and Speaker Identification Systems
- Accuracy on the line: on the strong correlation between out-of-distribution and in-distribution generalization
- Robust fine-tuning of zero-shot models
- Fine-tuning can distort pretrained features and underperform out-of-distribution

# People:
- [Aditi Raghunathan](https://scholar.google.com/citations?hl=en&user=Ch9iRwQAAAAJ&view_op=list_works&sortby=pubdate)
- [Percy Liang](https://scholar.google.com/citations?hl=en&user=pouyVyUAAAAJ&view_op=list_works&sortby=pubdate)

Also, there's a [course](https://sites.google.com/view/evalmodel) on this!

# Nice Ideas (for the next days):
- Make a playlist of songs:
  - Simge (Ben Bazen)
